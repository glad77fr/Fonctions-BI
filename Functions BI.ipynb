{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la fonction link_count est utilisée pour calculer les indicateurs. Elle permet de rattacher les date d'une source de données à des dates fin de mois puis de les compter (groupby).\n",
    "    \n",
    "def link_count( alim_dataFrame, target_dataFrame, left_keys, event_date, indicator_name, right_keys=None, type_conso=None):\n",
    "    # alim_dataFrame dataframe à alimenter\n",
    "    # target_dataFrame: dataframe contenant l'indicateur à récupérer\n",
    "    # left_keys : clés servant à réaliser la jointure sur le dataframe à alimenter\n",
    "    # event_date : date de l'\n",
    "    # event_name: nom de l'indicateur cible \n",
    "    # right_key : facultatif, nom des clés de jointure de droite dans le cas où ces dernière diffère de celle de gauche\n",
    "    \n",
    "    tr_target = target_dataFrame.copy()\n",
    "    tr_target[\"link_date\"] = tr_target[event_date].apply(lambda x: x.replace(day=x.days_in_month))\n",
    "    tr_target[\"link_date\"] = tr_target[\"link_date\"].astype(str)\n",
    "    tr_target[\"link_date\"] = tr_target[\"link_date\"].apply(lambda x: x[:10])\n",
    "    \n",
    "    tr_alim = alim_dataFrame[left_keys]\n",
    "\n",
    "    if right_keys == None:\n",
    "        right_keys = left_keys.copy()[:len(left_keys)-1]\n",
    "        right_keys.append(\"link_date\")    \n",
    "        result = tr_alim.merge(tr_target[right_keys], right_on = right_keys, left_on = left_keys, how='left')\n",
    "        \n",
    "        if type_conso == None:\n",
    "            result = result.groupby(left_keys)[\"link_date\"].count().reset_index()\n",
    "        if type_conso == \"unique\":\n",
    "            result = result.groupby(left_keys)[\"link_date\"].nunique().reset_index()\n",
    "            \n",
    "            print(result)\n",
    "            \n",
    "        result[indicator_name] = result[\"link_date\"]\n",
    "        result.drop([\"link_date\"], axis=1, inplace=True)\n",
    "        alim_dataFrame = alim_dataFrame.merge(result, on=left_keys, how='left')     \n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "            \n",
    "    return alim_dataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_date(dataframe, id_dataset, start_date, end_date):\n",
    "# La colonne to_delete contient les offres à supprimer, 1=> à supprimer\n",
    "\n",
    "    dataframe[start_date] = dataframe[start_date].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n",
    "    dataframe[end_date] = dataframe[end_date].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n",
    "\n",
    "  # Etape 1 : Filtre croissant sur id_dataset, start_date, end_date\n",
    "\n",
    "    dataframe = dataframe.sort_values(by=[id_dataset, start_date, end_date], ascending=[True, True, True])\n",
    "    dataframe[\"to_delete\"]= 0\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "\n",
    "  # Etape 2 : Si pour un même id la date de début inférieure ou égale à la date de fin de la ligne précédente et que la date de fin est inférieure ou égale à la date de fin de la ligne précédente\n",
    "  # Etape 2: on remplace cette date de fin par celle de la ligne précédente\n",
    "    for i, val in enumerate(dataframe.iterrows()):\n",
    "        if i!=0:\n",
    "            if dataframe.at[i, id_dataset] == dataframe.at[i-1, id_dataset]:\n",
    "                if dataframe.at[i,start_date]<= dataframe.at[i-1,end_date] :\n",
    "                    if dataframe.at[i,end_date]<= dataframe.at[i-1,end_date]:\n",
    "                        dataframe.at[i, end_date] = dataframe.at[i-1,end_date]\n",
    "  \n",
    "      dataframe.to_csv(r'/dbfs/FileStore/tables/Etape2.csv')\n",
    "  # Etape 3: On tri par date décroissante le dataset: id_dataset, start_date, end_date\n",
    "      dataframe = dataframe.sort_values(by=[id_dataset, start_date, end_date], ascending=[True, False, False])\n",
    "      dataframe = dataframe.reset_index(drop=True)\n",
    "  \n",
    "  # Etape 4: Pour un même id, si la date de fin est inférieure à la de debut de la ligne précédente, on ne fait rien\n",
    "  # Etape 4bisA: dans le cas contraire, si date de début de la ligne précédente -1 jour est inférieure ou égale à la date fin actuelle alors la date de fin actuelle est remplacée par ligne de fin de la ligne précédente\n",
    "  # Etape 4bisA: un flag to_delete est ajouté pour suppression pour l'avant dernière étape\n",
    "  # Etape 4bisB: dans le cas où date de début de la ligne précédente -1 jour est supérieur à la date de fin actuelle, on remplace la date de fin actuelle par la date début de la ligne précédente -1 jour\n",
    "\n",
    "        for i, val in enumerate(dataframe.iterrows()):\n",
    "            if i!=0:\n",
    "                if dataframe.at[i, id_dataset] == dataframe.at[i-1, id_dataset]:\n",
    "                    if dataframe.at[i, end_date] <  dataframe.at[i-1, start_date]:\n",
    "                        pass\n",
    "            else:\n",
    "                if (dataframe.at[i-1, start_date] - np.timedelta64(1,'D')) <= dataframe.at[i, start_date]:            \n",
    "                    dataframe.at[i, end_date] = dataframe.at[i, start_date]\n",
    "                if dataframe.at[i, start_date] == dataframe.at[i-1, start_date]:\n",
    "                    dataframe.at[i, \"to_delete\"] = 1\n",
    "            else:\n",
    "                dataframe.at[i, end_date] = dataframe.at[i-1, start_date] - np.timedelta64(1,'D')#np.timedelta64(1,'D') dt.timedelta(days=1)\n",
    "\n",
    "      # Etape 5: on supprimer les ligne à supprimer\n",
    "        dataframe = dataframe.loc[dataframe[\"to_delete\"] != 1]\n",
    "        dataframe[end_date] = dataframe[end_date].apply(lambda x: x.replace(hour=23, minute=59, second=59))\n",
    "\n",
    "      #Etape 6 : on supprime la colonne to_delete\n",
    "        dataframe = dataframe.drop([\"to_delete\"], axis=1)\n",
    "\n",
    "        return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(dataframe, id_dataset, start_date, end_date):\n",
    "    dataframe = dataframe.sort_values(by=[id_dataset, start_date])\n",
    "    dataframe[\"superposition\"] = 0\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "    \n",
    "    for i, val in enumerate(dataframe.iterrows()):\n",
    "        if i!=0:\n",
    "            if dataframe.at[i, id_dataset] == dataframe.at[i-1, id_dataset]:\n",
    "                if dataframe.at[i,start_date]<= dataframe.at[i-1,end_date]:\n",
    "                    dataframe.at[i, \"superposition\"] = 1\n",
    "                    dataframe.at[i-1,\"superposition\"] = 1\n",
    "    result = dataframe.loc[dataframe[\"superposition\"]==1]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_event_gen(dataframe, list_column_qual, list_column_date, list_indicator_names=None):\n",
    "  # dataframe correspond à la source de données à partir la table de fait va être générée\n",
    "  # list_column_qual\n",
    "  # list_column_date correspond à l'ensemble des colonnes date qui vont servir à générer la table de fait, la première colonne doit correspondre à la clé\n",
    "  # list_indicator_names correspond au nom des indicateurs, si elle est vide, le nom par défaut sera le nom des colonnes\n",
    "  # Indique la position du premier indicateur dans la list\n",
    "  \n",
    "    result = pd.DataFrame()\n",
    "  \n",
    "    for col in list_column_qual:\n",
    "        result[col]= \"\"\n",
    "\n",
    "\n",
    "    for i, column in enumerate(list_column_date):\n",
    "    \n",
    "        prep = pd.DataFrame()\n",
    "        list_col_prep = list_column_qual + [\"Event_Date\"]\n",
    "        list_col_target =list_column_qual + [column]\n",
    "        prep[list_col_prep] = dataframe[list_col_target]\n",
    "        prep = prep.loc[prep[\"Event_Date\"].notnull()].reset_index(drop=True)\n",
    "        prep[list_indicator_names[i]] = 1\n",
    "        result = pd.concat([result, prep], sort=False)\n",
    "        result = result.reset_index(drop=True)\n",
    "\n",
    "    for i, col in enumerate(list_indicator_names):\n",
    "        result.loc[result[col].isna()==True, col] = 0\n",
    "        result[col] = result[col].astype('int64')\n",
    "      \n",
    "    return result    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
